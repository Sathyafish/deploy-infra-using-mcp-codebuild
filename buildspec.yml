version: 0.2

env:
  variables:
    AWS_REGION: "us-east-1"
    INSTRUCTION: "Create an S3 bucket named my-company-logs-12345 with versioning enabled and block all public access."
    BEDROCK_MODEL_ID: "amazon.titan-text-premier-v1:0"
    TF_DIR: "tfgen"

phases:
  install:
    runtime-versions:
      python: 3.11
    commands:
      - python --version
      - pip install --upgrade pip
      - pip install "mcp[cli]" awslabs.terraform-mcp-server boto3
      - |
        # Install Terraform
        wget -q https://releases.hashicorp.com/terraform/1.6.6/terraform_1.6.6_linux_amd64.zip
        unzip -q terraform_1.6.6_linux_amd64.zip
        mv terraform /usr/local/bin/
        terraform -version

  pre_build:
    commands:
      - echo "Validating environment variables..."
      - |
        if [ -z "$INSTRUCTION" ]; then
          echo "ERROR - INSTRUCTION env var is required"
          exit 1
        fi
      - mkdir -p "$TF_DIR"
      - echo "Instruction - $INSTRUCTION"
      - echo "Region - $AWS_REGION"
      - echo "TF_DIR - $TF_DIR"

  build:
    commands:
      - |
        cat > nl_to_terraform_and_apply.py << 'PYEOF'
        import asyncio
        import json
        import os
        import textwrap

        import boto3
        from mcp import ClientSession, StdioServerParameters
        from mcp.client.stdio import stdio_client

        def bedrock_invoke_text(model_id: str, prompt: str) -> str:
            """
            Minimal Bedrock text invocation for Anthropic-style models.
            """
            br = boto3.client("bedrock-runtime", region_name=os.environ["AWS_REGION"])

            body = {
                "anthropic_version": "bedrock-2023-05-31",
                "max_tokens": 2000,
                "temperature": 0.2,
                "messages": [{"role": "user", "content": prompt}],
            }

            resp = br.invoke_model(
                modelId=model_id,
                body=json.dumps(body).encode("utf-8"),
                contentType="application/json",
                accept="application/json",
            )
            data = json.loads(resp["body"].read())
            return "".join(part.get("text", "") for part in data.get("content", []))

        def write_tf_files(tf_dir: str, main_tf: str) -> None:
            with open(os.path.join(tf_dir, "main.tf"), "w", encoding="utf-8") as f:
                f.write(main_tf.strip() + "\n")

        async def run_tf_mcp(tf_dir: str, aws_region: str, command: str) -> None:
            server_params = StdioServerParameters(
                command="uvx",
                args=["awslabs.terraform-mcp-server@latest"],
                env={
                    "AWS_REGION": aws_region,
                    "FASTMCP_LOG_LEVEL": "ERROR",
                },
            )

            async with stdio_client(server_params) as (read, write):
                async with ClientSession(read, write) as session:
                    await session.initialize()

                    result = await session.call_tool(
                        "ExecuteTerraformCommand",
                        arguments={
                            "command": command,
                            "working_directory": tf_dir,
                            "aws_region": aws_region,
                            "strip_ansi": True,
                        },
                    )

                    for part in result.content:
                        txt = getattr(part, "text", None)
                        if txt:
                            print(txt)

        async def main() -> None:
            instruction = os.environ["INSTRUCTION"].strip()
            aws_region = os.environ["AWS_REGION"]
            model_id = os.environ["BEDROCK_MODEL_ID"]
            tf_dir = os.environ["TF_DIR"]

            system_rules = textwrap.dedent(f"""
            You are generating Terraform for AWS based on a single natural-language instruction.
            Requirements:
            - Output ONLY valid Terraform HCL for main.tf (no markdown, no explanations).
            - Use the AWS provider.
            - Prefer secure defaults: block public access for S3, enable versioning if asked, no public ACL/policy.
            - Keep it minimal: only resources required by the instruction.
            - Region: {aws_region}
            """)

            prompt = system_rules + "\nInstruction:\n" + instruction + "\n"

            print("Generating Terraform with Bedrock...")
            main_tf = bedrock_invoke_text(model_id, prompt)
            if not main_tf.strip():
                raise RuntimeError("LLM returned empty Terraform.")

            write_tf_files(tf_dir, main_tf)
            print("Generated main.tf:")
            print(main_tf)

            print("\n=== terraform init (via MCP) ===")
            await run_tf_mcp(tf_dir, aws_region, "init -upgrade")

            print("\n=== terraform validate (via MCP) ===")
            await run_tf_mcp(tf_dir, aws_region, "validate")

            print("\n=== terraform plan (via MCP) ===")
            await run_tf_mcp(tf_dir, aws_region, "plan -out=tfplan")

            print("\n=== terraform apply (via MCP) ===")
            await run_tf_mcp(tf_dir, aws_region, "apply -auto-approve tfplan")

        if __name__ == "__main__":
            asyncio.run(main())
        PYEOF
      - python nl_to_terraform_and_apply.py

  post_build:
    commands:
      - echo "Deployment complete!"
      - ls -la $TF_DIR

artifacts:
  files:
    - tfgen/main.tf
    - nl_to_terraform_and_apply.py
  name: terraform-mcp-artifacts